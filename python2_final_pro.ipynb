{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd   \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pylab as pl\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#חלק 1\n",
    "\n",
    "#שאלה ראשונה - האם ניתן לחזות או להעריך את מחיר הטיסה של טיסת פנים בהודו על סמך נתיב, חברת תעופה או תאריך?\n",
    "\n",
    "#Specific -לפנינו שאלה עסקית, עליה ניתן לענות באמצעות חיזוי מכיוון שהנתונים מכילים מידע ספציפי לגבי הטיסות, שכולל תאריכים, שעות ומסלולים ספציפיים, ולהם מחיר ספציפי משתנה לכל טיסה. \n",
    "#Measurable -  ניתן למדוד את יכולת דיוק החיזוי שלנו (כמה ממחירי הטיסות נצליח לחזות לפי הפרמרטים המבוקשים)\n",
    "#Assignable - ניתן להגדיר שלבים אל עבר התשובה הסופית ולחלק לכל סטודנט חלק מהשלבים בעשייה, בהם בחירת הנתונים הרלוונטיים, סינון המידע,אינטגרציה, אימון וחיזוי.  \n",
    "#Realistic - .כן, מכיוון שמדובר בבעיית , אנו מכירים את הנתונים מראש. supervised \n",
    "#Time-Related - ניתן לחלק את השלבים לזמנים. ביום הראשון למדנו ובחרנו את הנתונים הרלוונטיים. \n",
    "#ביומיים לאחר מיכן סיננו את המידע וביצענו אינטגרציה על הנתונים.\n",
    "#ביומיים האחרונים ביצענו אימון וחיזוי , הסקנו מסקנות וכתבנו דוח.\n",
    "\n",
    "# :שאלה שניה - לכמה קבוצות ניתן לחלק את הטיסות כך שבכל קבוצה תהיינה טיסות אשר דומות אחת לשניה\n",
    "#מבחינת חברה תעופה, נתיב וכו׳?\n",
    "\n",
    "#Specific - השאלה אכן ספציפית , מכיוון שאנו יודעים על פי אילו קריטריונים יש לחלק את הטיסות לקבוצות בכדי שיהיו דומות.\n",
    "#Measurable - מכיוון שיש לנו סט נתונים שמעיד על כל מסלולי הטיסות ושאר המאפיינים של אותם המסלולים , ניתן באמצעות ניתוח מתאים לענות על כמה קבוצות טיסה ניתן לחלק את הטיסות כך שהקבוצות יכילו טיסות דומות. \n",
    "#Assignable - ניתן להגדיר שלבים אל עבר התשובה הסופית ולחלק לכל סטודנט חלק מהשלבים , בהם בחירת הנתונים הרלוונטיים סינון המידע,אינטגרציה, אימון וחיזוי.  \n",
    "#Realistic - unsupervised , עקב כך שמדובר בבעיית \n",
    "#בעוד שהנתנונים הצפויים להימצא בעמודות אכן קיימים , האלגורתים יוכל למצוא דמיון כלשהו בין הטיסות ולבצע את החלוקה האופטימלית.\n",
    "#Time-Related - ניתן לחלק את השלבים את לזמנים. ביום הראשון למדנו ובחרנו את הנתונים הרלוונטיים. \n",
    "#ביומיים לאחר מיכן סיננו את המידע וביצענו אינטגרציה על הנתונים.\n",
    "#ביומיים האחרונים ביצענו אימון וחיזוי , הסקנו מסקנות וכתבנו דוח.\n",
    "\n",
    "\n",
    "#חלק 2\n",
    "\n",
    "###שאלה ראשונה\n",
    "\n",
    "#כפי שניתן לראות יש קשר בין הנתונים בעמודות ״נתיב״ , ״חברת תעופה״ , ו״תאריך״ לעמודת המחיר של טיסות הפנים של הודו. עמודת המחיר תלויה בעמודות אלו ולכן ניתן לנסות לחזות או להעריך את המחיר.\n",
    "#.עבור אוסף הנתונים של מחירי הטיסות נרצה לנתח את נתוני הטיסות עצמן (שאר מאפיינה, כגון מסלול,חברת תעופה וכו׳) שכן, הם אלו שמשפיעים על המחיר באופן ישיר.)\n",
    "# נתחיל בלהציג כדוגמא חלק ממצועי המחירים לפי חברות התעופה השונות על מנת לתת תחושה ראשונית לגבי ההשפעת חברות התעופה השונות על המחיר ומה ממוצע המחירים כשאר טסים עם החברות הללו.נתונות מספר דוגמאות.\n",
    "\n",
    "###שאלה שניה\n",
    "\n",
    "#לאחר שנראה שהעמודות אכן מכילות את הנתונים אשר הן צפויות להכיל בעמודות ״חברת תעופה״, ״נתיב״, וכדומה. \n",
    "#המשכנו עם שלב עיבוד המידע וניסינו למצוא דרך לחלק את הטיסות לקבוצות, לכן בחרנו בשיטת הקלאסטרינג. בשיטה\n",
    "#זו המחשב מבצע חלוקה לקבוצות על סמך מאפיינים דומים ובאמצעות שיטה זו נוכל להגיע לחלוקה האופטימלית.\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    data = pd.read_excel(\"flights.xslx.csv\")\n",
    "    #data = pd.read_csv(\"flights.csv\")\n",
    "    print(\"loaded.\") \n",
    "    print(data)\n",
    "except:\n",
    "    print(\"Error\")\n",
    "\n",
    "    \n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "\n",
    "print(data[\"Airline\"].value_counts())\n",
    "      \n",
    "print(\"\\n\\n\\nAvereage price for each Airline: \\n\\n\\n\",data.groupby([\"Airline\"]).mean())\n",
    "print(\"\\n\\n\")\n",
    "data.plot(kind='scatter',x='Price',y='Airline',color='red')\n",
    "plt.show()\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "#מהגרף ניתן ללמוד שמתאפשר לדעת מהו טווח המחירים לפי כל חברת תעופה.\n",
    "\n",
    "data[\"Route\"].value_counts()\n",
    "#נבדוק כמה מסלולים שונים יש ומה שכיחותם\n",
    "#ראינו שיש מסלולים רבים\n",
    "\n",
    "#3  חלק א\n",
    "\n",
    "#3.1\n",
    "\n",
    "#תחקור סטטיסטי בסיסי\n",
    "\n",
    "print(\"Price data:\\n \",data[\"Price\"].describe())\n",
    "\n",
    "print(\"\\n\\n\\n\\n\\n\\nThe most visited destinations in descending order: \", data[\"Destination\"].value_counts())\n",
    "\n",
    "print(\"\\n\\n\\n\\n\\n\\nThe most popular Airline is:\",data[\"Airline\"].value_counts().reset_index()[\"index\"][0])\n",
    " \n",
    "print(\"\\n\\n\\n\\n\\n\\nThe Types of additional info: \", data[\"Additional_Info\"].value_counts())\n",
    "\n",
    "uncommon_source = data[\"Source\"].value_counts().reset_index()[\"index\"]\n",
    "print(\"\\n\\n\\n\\n\\n\\nThe most uncommon Source is: \",  uncommon_source[len(uncommon_source)-1])    \n",
    "\n",
    "print(\"\\n\\n\\n\\n\\n\\nThe date in which there were the most filghts is: \", data[\"Date\"].value_counts().reset_index()[\"index\"][0])    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#3.2\n",
    "#הצגת התפלגויות על פי גרפים\n",
    "\n",
    "print(\"\\nDistribution of the amount of flights to different destinations:\\n\\n\")\n",
    "data[\"Destination\"].value_counts(sort=True).nlargest(10).plot.bar()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")\n",
    "\n",
    "print(\"\\nDistribution of filghts from different sources:\\n\\n\")\n",
    "data[\"Source\"].value_counts().plot.pie(autopct='%.2f') \n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Airlines:\\n\\n\\n\")\n",
    "data[\"Airline\"].value_counts().plot(kind='barh', figsize=(8, 6), color=\"black\")\n",
    "plt.xlabel(\"Amount of flights\", labelpad=14)\n",
    "plt.ylabel(\"Airlines\", labelpad=14)\n",
    "plt.title(\"Distribution of different Airlines:\", y=1.02);\n",
    "plt.show()\n",
    "\n",
    "#3.3 \n",
    "#הכנת הנתונים לחקירה\n",
    "\n",
    "data['Duration']=  data['Duration'].str.replace(\"h\", '*60').str.replace(' ','+').str.replace('m','*1').apply(eval)\n",
    "print(\"The avereage time for a flight in minutes is: \", data['Duration'].mean())\n",
    "\n",
    "\n",
    "data[\"Dep_Time\"] = data[\"Dep_Time\"].apply(lambda num: num.replace(\":\",\"\") )\n",
    "print(\"The latest hour in which a flight has occured is: \", data[\"Dep_Time\"].max())   \n",
    "data[\"Dep_Time\"] = pd.to_numeric(data[\"Dep_Time\"],errors='coerce')\n",
    "\n",
    "\n",
    "data[\"Date\"] = data[\"Date\"].apply(lambda date: date.replace(\"/\",\"\") )\n",
    "data[\"Date\"] = pd.to_numeric(data[\"Date\"],errors='coerce')\n",
    "\n",
    "\n",
    "#3 continue\n",
    "\n",
    "#1\n",
    "\n",
    "#מחיקת ערכים חסרים במידה ויש\n",
    "data = data.dropna()     \n",
    "\n",
    "#2\n",
    "\n",
    "\n",
    "\n",
    "data_classification = data\n",
    "\n",
    "#data                ==> clustering\n",
    "#data_classification ==> classification\n",
    "\n",
    "\n",
    "\n",
    "#פעולות על clustering\n",
    "\n",
    "\n",
    "#3a\n",
    "data = data[[\"Airline\", \"Source\", \"Destination\", \"Price\"]]\n",
    "#3b\n",
    "data = pd.get_dummies(data)\n",
    "#3c\n",
    "\n",
    "\n",
    "scaler1 = MinMaxScaler()\n",
    "data = pd.DataFrame(scaler1.fit_transform(data) , columns = data.columns)\n",
    "print(\"\\n\\n\\n\\n\\n\\n\\clustering data after MinMax scaler:\\n\", data)    #הדפסת בדיקה\n",
    "\n",
    "\n",
    "#4a\n",
    "\n",
    "print(\"\\n\\nChecking which Airlines do we have:\",data_classification[\"Airline\"].value_counts()) #בדיקה שלנו\n",
    "\n",
    "Air_dict = {\"Air Asia\": 1 , \"Air India\" : 2 , \"GoAir\": 3 \n",
    "           , \"IndiGo\": 4 , \"Jet Airways\": 5,\"Jet Airways Business\":6 ,\n",
    "           \"Multiple carriers\":7 ,\"Vistara\":8, \"Multiple carriers Premium economy\":9 ,\"SpiceJet\":10, \"Vistara Premium economy\":11, \"Trujet\":12   }\n",
    "data_classification[\"Airline\"] = data_classification[\"Airline\"].map(Air_dict)\n",
    "\n",
    "\n",
    "print(\"Airline check:\",data_classification) #הדפסת בדיקה\n",
    "\n",
    "\n",
    "#4b \n",
    "\n",
    "#it's better to delete this column even before \"e\" so we won't get a huge amount of columns that we will delete soon anyway.\n",
    "#עדיף למחוק את העמודה הזו כבר עכשיו בכדי שלא נקבל מספר עצום של עמודות שיש למחוק ממיילא כמה סעיפים לאחר מיכן.\n",
    "data_classification = data_classification.drop(columns = \"Arrival_Time\") \n",
    "\n",
    "\n",
    "data_classification = pd.get_dummies(data_classification)\n",
    "#עמודת איירליין לא תושפע מהפעולה הזו מכיוון שהעמודה כבר נומרית ולא קטגוריאלית.\n",
    "\n",
    "#4c \n",
    "\n",
    "data_classification[\"Price\"].loc[data_classification[\"Price\"] < 7000] = 1 \n",
    "data_classification[\"Price\"].loc[(data_classification[\"Price\"] >= 7000) & (data_classification[\"Price\"] <= 14000)] = 2\n",
    "data_classification[\"Price\"].loc[data_classification[\"Price\"] > 14000] = 3\n",
    "print(\"\\n\\n\\n\\nchanging price:\",data_classification)\n",
    "\n",
    "#d\n",
    "\n",
    "data_classification[\"Date\"] = data_classification[\"Date\"].astype(str)\n",
    "data_classification[\"Date\"] = data_classification[\"Date\"].apply(lambda date:  date[2]+date[3] if len(date)==8 else  date[1]+date[2])\n",
    "data_classification[\"Date\"] = data_classification[\"Date\"].apply(lambda date:  date[1] if date[0]==\"0\" else date )\n",
    "\n",
    "\n",
    "#e\n",
    "#מחיקת שאר העמודות שביקשו\n",
    "\n",
    "data_classification = data_classification.drop(columns = \"Dep_Time\")\n",
    "data_classification = data_classification.drop(columns = \"Duration\")\n",
    "\n",
    "#f   \n",
    "\n",
    "x = data_classification.drop(columns = [\"Price\"])\n",
    "y = data_classification[\"Price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size = 0.25)\n",
    "print(\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")\n",
    "print(f\"X train shape: {X_train.shape}, X test shape: {X_test.shape} y train: {y_train.shape}, y test: {y_test.shape}\")\n",
    "\n",
    "\n",
    "#חלק 4\n",
    "\n",
    "#kmeans\n",
    "\n",
    "\n",
    "measures1_sil = []\n",
    "\n",
    "measures1 = {\n",
    "    \"K1\": range(2,11), \"SSE1\":[]\n",
    "}\n",
    "for k1 in measures1[\"K1\"]:\n",
    "    kmeans1 = KMeans(n_clusters = k1 , init= \"k-means++\")\n",
    "    kmeans1.fit(data)    \n",
    "    measures1[\"SSE1\"].append(kmeans1.inertia_)   \n",
    "    measures1_sil.append(metrics.silhouette_score(data, kmeans1.labels_))\n",
    "   \n",
    "print(\"\\n\\n\\n\\n\\n\\n\")\n",
    "measures1 = pd.DataFrame(measures1)\n",
    "measures1.set_index(\"K1\", inplace = True)\n",
    "\n",
    "print(measures1.plot())\n",
    "#ניתן לראות לפי שיטת המרפק שהקיי האופטימלי הוא 3 , זאת היות וזו נקודת השבירה החדה הראשונה\n",
    "\n",
    "\n",
    "print(\"\\n\\nSilhouette score for all each K:\" ,measures1_sil)     \n",
    "print(\"silhouette score for K = 3 (best k) is: \",measures1_sil[1] )\n",
    "\n",
    "\n",
    "#   measures1 = סכום הטעויות\n",
    "#   measures1_sil = מדדי הסילואט\n",
    "\n",
    "\n",
    "#RandomForest\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 25)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "#חלק 5\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\\nSSE:\" ,measures1)\n",
    "#סכום הטעויות\n",
    "\n",
    "\n",
    "print(\"Accuracy forest: \", metrics.accuracy_score(y_test,rf_pred))\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, rf_pred)\n",
    "print(\"\\n\\n\\nconfusion_matrix_forest:\\n\",cm)\n",
    "\n",
    "\n",
    "#מטריצת הבילבול לרנדום פורסט\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CRISP-DM דוח מסכם על פי שלבי\n",
    "\n",
    "הבנת צורך עסקי - Understanding Business שלב ראשון \n",
    "המטרה העיקרית בשלב זה הוא לסמן את הנקודות החשובות, כך שבמהלך התהליך נוכל\n",
    ".להתכנס ולענות על נקודות אלו\n",
    "\n",
    ".שלב זה הוגדר לנו מראש\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Data Understanding - שלב שניי  \n",
    "\n",
    "\n",
    "\n",
    "בשלב זה השתמשנו בפונקציות שונות על מנת להבין כיצד נראים הנתונים, מה הם מייצגים, מה קיים וכו׳. \n",
    "ראינו שהנתונים מייצגים מידע לגבי טיסות פנים בהודו.\n",
    "\n",
    "עבור כל אחת מהשאלות העיסקיות ראינו שניתן לענות בהתבסס על הנתונים. הצגנו \n",
    "נתונים כלליים בנוגע לטיסות והצגנו דיאגרמה שהראתה טווח מחירים לפי כל חברת תעופה.\n",
    "בנוסף הצגנו את המחיר הממוצע פר חברת תעופה.\n",
    "\n",
    "\n",
    "Data Preparation - שלב שלישי \n",
    "\n",
    "ראשית ראינו בכמה מהטיסות בנתונים מופיעה כל חברת תעופה , כל יעד , כל מקור. לאחר מיכן גילינו מיהי חברת התעופה השכיחה ביותר בנתונים, מי היעד המבוקש ביותר ומי המקור שטסים ממנו הכי מעט. בנוסף בדקנו מהם הסוגים השונים של ה״המידע הנוסף״\n",
    "שהיה קשור לכל טיסה.\n",
    "\n",
    ",בהמשך הנגשנו את הנתונים לשלב הניתוח באמצעות ניקוי ערכים חסרים, המרת עמודת חברות התעופה לנומרית \n",
    "הנגשת עמודת זמן ההמראה ועוד.\n",
    "בנוסף ביצענו מספר פעולות על מנת להציג את הערכים וכמויותיהם בעמודות השונות על ידי\n",
    "value_counts\n",
    "\n",
    "\n",
    "Modeling - שלב רביעי \n",
    "\n",
    "בחלק זה הרצנו מודל קלאסטרינג בעזרת אלגוריתם קיי מינס. \n",
    "מכיוון שמדובר בבעיית supervised, \n",
    "בעיה בה כן יש לנו סט נתונים מתוייג.\n",
    "\n",
    "\n",
    "בנוסף לכך הרצנו מופע של רנדום פורסט המשתמש ב25 עצים שונים עבור מודל קלאסיפיקיישן.\n",
    "\n",
    "\n",
    "\n",
    "Evaluation - שלב חמישי \n",
    "\n",
    "בשלב זה הצגנו בצורה מפורטת את התוצאות מחלק 4.\n",
    "\n",
    "עבור מודל הקיי מינס,(שבוצע על הקלאסטרינג דאטה) הצגנו את המערך אליו הכנסנו את כל מדדי הסילואט ובנוסף הדפסנו את מדד הסילואט של הקיי האופטימלי, שגילינו שהוא שלוש.\n",
    "SSEכמו כן, הצגנו את ה\n",
    "כעמודה ובגרף עם כל שאר הקיי עליהם הרצנו את האלגוריתם (לפי מה שהוגדר לנו).\n",
    "\n",
    "\n",
    "\n",
    "הרצנו את מופע הרנדום פורסט(שבוצע על הקלאסיפיקיישן דאטה, 25 עצים)והצגנו את מטריצת הבילבול שניתן לסכמה במדד הדיוק .שנמצא בטווח 0.8-0.7 \n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "מסקנות:\n",
    "\n",
    "שאלה ראשונה - \n",
    "ממופע הרנדום פורסט \n",
    "\n",
    "לאחר הצגת מטריצת הבילבול ואחוז הדיוק אשר שנמצא בטווח 0.8-0.7 \n",
    "ניתן ללמוד שהצלחנו לחזות בדיוק די גבוה את מחירי טיסות הפנים של הטיסות בהודו על סמך עמודת הנתיב חברת התעופה והתאריך (בתאריך הכוונה לחודש)\n",
    "\n",
    "שאלה שניה - \n",
    "מהאלגוריתם של הקיי מינס למדנו את התשובה לשאלה \n",
    "לכמה קבוצות ניתן לחלק את הטיסות כך שבכל קבוצה תהיינה טיסות אשר דומות אחת לשניה\n",
    "? מבחינת חברה תעופה, נתיב וכו\n",
    "התשובה שעלתה היא שהחלוקה המיטבית תהיה ל3 קבוצות דומות.\n",
    "\n",
    "מדד הסילואט מלמד אותנו עד כמה החלוקה היתה מוצלחת.\n",
    "מדד הסילואט יצא לנו סביב 0.43 , ומכך ניתן ללמוד שהחלוקה היתה ביו טובה לשנויה במחלוקת מכיוון שהערך נמצא בטווח בין\n",
    "אפס לאחד.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
